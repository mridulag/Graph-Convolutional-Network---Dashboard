{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd \n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install dgl",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e800310da432de0abb968175ec231b0219447620"
      },
      "cell_type": "code",
      "source": "#adding features and formatting data\nimport scipy.sparse as sp\n\ndef load_data(path=\"../input/terrorattack/TerrorAttack/\", dataset=\"TerrorAttack\"):\n    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n    print('Loading {} dataset...'.format(dataset))\n    \n    idx_features_labels = np.genfromtxt(\"../input/terrorattack/TerrorAttack/terrorist_attack.nodes\",\n                                        np.dtype(str),comments=None)\n\n    print(idx_features_labels)\n    \n    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n    print(features)\n    \n    labels = encode_onehot(idx_features_labels[:, -1])\n    \n    idx = np.array(idx_features_labels[:, 0], dtype=None)\n\n    idx_map = {j: i for i, j in enumerate(idx)}\n    \n    edges_unordered = np.genfromtxt(\"../input/terrorattack/TerrorAttack/terrorist_attack_loc.edges\",\n                                    np.dtype(str),comments=None)\n    \n    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n                     dtype=np.int32).reshape(edges_unordered.shape)\n    \n    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n                        shape=(labels.shape[0], labels.shape[0]),\n                        dtype=np.float32)\n    \n    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n\n    features = normalize(features)\n    adj = normalize(adj + sp.eye(adj.shape[0]))\n    \n    idx_train = range(1200) #originally (180)\n    idx_val = range(500, 1000) #originally (200,500)\n    idx_test = range(1000, 1293) #originally (500,1500)\n\n    features = torch.FloatTensor(np.array(features.todense()))\n    labels = torch.LongTensor(np.where(labels)[1])\n    adj = sparse_mx_to_torch_sparse_tensor(adj)\n\n    idx_train = torch.LongTensor(idx_train)\n    idx_val = torch.LongTensor(idx_val)\n    idx_test = torch.LongTensor(idx_test)\n    \n    return adj, features, labels, idx_train, idx_val, idx_test\n\ndef normalize(mx):\n    \"\"\"Row-normalize sparse matrix\"\"\"\n    rowsum = np.array(mx.sum(1))\n    r_inv = np.power(rowsum, -1).flatten()\n    r_inv[np.isinf(r_inv)] = 0.\n    r_mat_inv = sp.diags(r_inv)\n    mx = r_mat_inv.dot(mx)\n    return mx\n\nall_lab=[]\ndef accuracy(output, labels):\n    all_lab.append(labels)\n    preds = output.max(1)[1].type_as(labels)\n    correct = preds.eq(labels).double()\n    correct = correct.sum()\n    return correct / len(labels)\n\n\ndef sparse_mx_to_torch_sparse_tensor(sparse_mx):\n    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n    indices = torch.from_numpy(\n        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n    values = torch.from_numpy(sparse_mx.data)\n    shape = torch.Size(sparse_mx.shape)\n    return torch.sparse.FloatTensor(indices, values, shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fae681c4b6483afb92bec7f59727fd657c926cd0"
      },
      "cell_type": "code",
      "source": "#one hot encoding\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef encode_onehot(labels):\n    classes = set(labels)\n    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n                    enumerate(classes)}\n    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n                         dtype=np.int32)\n    print(labels_onehot)\n    return labels_onehot",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a727dad3cb835410fcde2d8e5f3f3bf326cbd32"
      },
      "cell_type": "code",
      "source": "#graph format\nimport dgl\nimport scipy.sparse as sp\nimport networkx as nx\ng = dgl.DGLGraph()\n\ng.add_nodes(1293)\n\nidx_features_labels = np.genfromtxt(\"../input/terrorattack/TerrorAttack/terrorist_attack.nodes\",\n\n                                        np.dtype(str),comments=None)\n\n\nfeatures = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n\nlabels = encode_onehot(idx_features_labels[:, -1])\nidx = np.array(idx_features_labels[:, 0], dtype=None)\n\nidx_map = {j: i for i, j in enumerate(idx)}\n\nedges_unordered = np.genfromtxt(\"../input/terrorattack/TerrorAttack/terrorist_attack_loc.edges\",\n\n                                np.dtype(str),comments=None);\nedges = np.array(list(map(idx_map.get, edges_unordered.flatten())),dtype=np.int32).reshape(edges_unordered.shape)\n\nsrc, dst = tuple(zip(*edges));\n\ng.add_edges(src, dst);\n\ng.add_edges(dst, src);\n\nprint('We have %d nodes.' % g.number_of_nodes())\n\nprint('We have %d edges.' % g.number_of_edges())\n\nnx_G = g.to_networkx().to_undirected()\npos = nx.kamada_kawai_layout(nx_G)\n\nnx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d01039b1d2f463c9ef09dc778ad0ba22bc9593bb"
      },
      "cell_type": "code",
      "source": "import torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n# Define the message & reduce function\n# NOTE: we ignore the GCN's normalization constant c_ij for this tutorial.\ndef gcn_message(edges):\n    # The argument is a batch of edges.\n    # This computes a (batch of) message called 'msg' using the source node's feature 'h'.\n    return {'msg' : edges.src['h']}\n\ndef gcn_reduce(nodes):\n    # The argument is a batch of nodes.\n    # This computes the new 'h' features by summing received 'msg' in each node's mailbox.\n    return {'h' : torch.sum(nodes.mailbox['msg'], dim=1)}\n\n# Define the GCNLayer module\nclass GCNLayer(nn.Module):\n    def __init__(self, in_feats, out_feats):\n        super(GCNLayer, self).__init__()\n        self.linear = nn.Linear(in_feats, out_feats)\n\n    def forward(self, g, inputs):\n        # g is the graph and the inputs is the input node features\n        # first set the node features\n        g.ndata['h'] = inputs\n        # trigger message passing on all edges \n        g.send(g.edges(), gcn_message)\n        # trigger aggregation at all nodes\n        g.recv(g.nodes(), gcn_reduce)\n        # get the result node features\n        h = g.ndata.pop('h')\n        # perform linear transformation\n        return self.linear(h)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "598b487205bde4f8dd19656135e4b3cc3305c55f"
      },
      "cell_type": "code",
      "source": "# Define a 2-layer GCN model\nclass GCN(nn.Module):\n    def __init__(self, in_feats, hidden_size, num_classes):\n        super(GCN, self).__init__()\n        self.gcn1 = GCNLayer(in_feats, hidden_size)\n        self.gcn2 = GCNLayer(hidden_size, num_classes)\n\n    def forward(self, g, inputs):\n        h = self.gcn1(g, inputs)   \n        h = torch.relu(h)\n        h = self.gcn2(g, h)\n        return h\n\nnet = GCN(1293, 16, 6)\nprint(net)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7e581d467f1b7138066bb8011608bf3638dcacd"
      },
      "cell_type": "code",
      "source": "import torch\ninputs = torch.eye(1293)\nprint(inputs)\n\nlabeled_nodes = torch.tensor([200,400, 600,800,1000,0])  \nprint(labeled_nodes)\nlabels = torch.tensor([0, 1,2,3,4,5])\nprint(labels)# their labels are different",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dfa5d8ca6c3bb7dfdc628e46574bad73042aa913",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "#training\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nall_logits = []\nfor epoch in range(205):\n    logits = net(g, inputs)\n    all_logits.append(logits.detach())\n  \n    logp = F.log_softmax(logits, 1)\n\n    loss = F.nll_loss(logp[labeled_nodes], labels)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a85492aa42ca966fce2789ff42340631229deec"
      },
      "cell_type": "code",
      "source": "#reducing dimentionality\nfrom sklearn.manifold import TSNE\nfrom matplotlib import pyplot as plt\ntsne_data1=[]\ni=0\nepochess=[]\nwhile(i<201):\n    outp=all_logits[i]\n    data_1000=outp\n    md=TSNE(n_components=2,random_state=0,perplexity = 50,learning_rate  = 100, n_iter=5000)\n    tsne_data=md.fit_transform(data_1000)\n    tsne_data1.append(tsne_data.tolist())\n    epochess.append(i)\n    i=i+1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0dd917821f500f7f74b2f67e66156185fc86febb"
      },
      "cell_type": "code",
      "source": "print(len(tsne_data1[0][0]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "739f2bff5dae26c9da125ad18db8807c749c3e95"
      },
      "cell_type": "code",
      "source": "import matplotlib.animation as animation\nimport matplotlib.pyplot as plt\nepoc=[]\ngroup=[]\ndef draw(i):\n    cls1color = '#9B59B6'\n    cls2color = '#F7DC6F'\n    cls3color = 'black'\n    cls4color = 'yellow'\n    cls5color = 'green'\n    cls6color = 'red'\n    pos = {}\n    dos = {}\n    colors = []\n    lab=[]\n    for v in range(1293):\n        ld=[]\n        dos[v] = all_logits[i][v].numpy()\n        cls = dos[v].argmax() # returns index of highest \n        lab.append(cls)\n        a=np.array(tsne_data1[i][v])\n        pos[v] = tsne_data1[i][v]\n        if(cls==0):\n            colors.append(cls1color)\n        elif(cls==1):\n            colors.append(cls2color)\n        elif(cls==2):\n            colors.append(cls3color)\n        elif(cls==3):\n            colors.append(cls4color)  \n        elif(cls==4):\n            colors.append(cls5color)\n        elif(cls==5):\n            colors.append(cls6color) \n        epoc.append(i)\n        #print(pos)\n    group.append(lab)\n    ax.cla()\n    ax.axis('off')\n    ax.set_title('Epoch: %d' % i)\n    nx.draw_networkx(nx_G.to_undirected(), pos, node_color=colors,\n           with_labels=False, node_size=10, ax=ax)\n    \nfig = plt.figure(dpi=150)\nfig.clf()\nax = fig.subplots()\n\ndraw(200)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "20338d5e54d40fc64b0a2ae838ec176f3be99283"
      },
      "cell_type": "code",
      "source": "ani = animation.FuncAnimation(fig, draw, frames=len(all_logits), interval=201)\nani.save('pickup_animation.gif', writer='imagemagick', fps=10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "25f0925848de1fe434db6de2f25bcceefaa598eb"
      },
      "cell_type": "code",
      "source": "#writing data to csv\nfrom sklearn.manifold import TSNE\nfrom matplotlib import pyplot as plt\nimport pandas as pd\ni = 0\nwhile i<201:\n    outp=all_logits[i]\n    data_1000=outp\n    print(group[i])\n    md=TSNE(n_components=2,random_state=0,perplexity = 50,learning_rate  = 100, n_iter=5000)\n    tsne_data1=md.fit_transform(data_1000)#Apply TSNE on the 190 iter\n    tsne_data1=np.vstack((group[i],tsne_data1.T)).T #Stack \n    tsne_df=pd.DataFrame(data=tsne_data1,columns=[\"label\",\"Dim_1\",\"Dim_2\"])\n    tsne_df[\"Epochs\"] = i\n    export_csv = tsne_df.to_csv ('files.csv',mode=\"a\", index = None, header=False)\n    print(\"iteraction - \", i)\n    i = i+10",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}