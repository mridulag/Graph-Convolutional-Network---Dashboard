{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb1e280a26ce462af7cbc02486694b0cbf5d0d7e"
      },
      "cell_type": "code",
      "source": "%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0581e3b9ab4400456a8a99e2e4ea76407267b668"
      },
      "cell_type": "markdown",
      "source": "\n\n"
    },
    {
      "metadata": {
        "_uuid": "bfd74db225b83dc0d66aca2b6f0900e2880055b9"
      },
      "cell_type": "markdown",
      "source": "\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cae00b32cba2740df9db854eb2fefcb30ad3d9a0"
      },
      "cell_type": "code",
      "source": "!pip install dgl",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "228bf5878dbcdaa64e973a5ea65d2385a349d50b"
      },
      "cell_type": "code",
      "source": "import dgl\n\ndef build_karate_club_graph():\n    g = dgl.DGLGraph()\n    # add 34 nodes into the graph; nodes are labeled from 0~33\n    g.add_nodes(34)\n    # all 78 edges as a list of tuples\n    edge_list = [(1, 0), (2, 0), (2, 1), (3, 0), (3, 1), (3, 2),\n        (4, 0), (5, 0), (6, 0), (6, 4), (6, 5), (7, 0), (7, 1),\n        (7, 2), (7, 3), (8, 0), (8, 2), (9, 2), (10, 0), (10, 4),\n        (10, 5), (11, 0), (12, 0), (12, 3), (13, 0), (13, 1), (13, 2),\n        (13, 3), (16, 5), (16, 6), (17, 0), (17, 1), (19, 0), (19, 1),\n        (21, 0), (21, 1), (25, 23), (25, 24), (27, 2), (27, 23),\n        (27, 24), (28, 2), (29, 23), (29, 26), (30, 1), (30, 8),\n        (31, 0), (31, 24), (31, 25), (31, 28), (32, 2), (32, 8),\n        (32, 14), (32, 15), (32, 18), (32, 20), (32, 22), (32, 23),\n        (32, 29), (32, 30), (32, 31), (33, 8), (33, 9), (33, 13),\n        (33, 14), (33, 15), (33, 18), (33, 19), (33, 20), (33, 22),\n        (33, 23), (33, 26), (33, 27), (33, 28), (33, 29), (33, 30),\n        (33, 31), (33, 32)]\n    # add edges two lists of nodes: src and dst\n    src, dst = tuple(zip(*edge_list))\n    g.add_edges(src, dst)\n    # edges are directional in DGL; make them bi-directional\n    g.add_edges(dst, src)\n\n    return g",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c73090772cce2740eb571d84343ca027fb462684"
      },
      "cell_type": "markdown",
      "source": "We can print out the number of nodes and edges in our newly constructed graph:\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "000955b7c44d90f0acbd25e97d35de5c60166081",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "G = build_karate_club_graph()\nprint('We have %d nodes.' % G.number_of_nodes())\nprint('We have %d edges.' % G.number_of_edges())\nprint(G)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "63b9c2da73dadd91f8dd4fe9221792e2f2aa7184"
      },
      "cell_type": "markdown",
      "source": "We can also visualize the graph by converting it to a `networkx\n<https://networkx.github.io/documentation/stable/>`_ graph:\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1063bbd977e8926fff179b965bcb1f7293f936b",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "import networkx as nx\n# Since the actual graph is undirected, we convert it for visualization\n# purpose.\nnx_G = G.to_networkx().to_undirected()\n# Kamada-Kawaii layout usually looks pretty for arbitrary graphs\npos = nx.kamada_kawai_layout(nx_G)\nprint(pos)\nprint(\"mm\",nx_G)\nnx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "375be7dda802bd0e7ac225ff38b888688f9cd6f4"
      },
      "cell_type": "markdown",
      "source": "Step 2: assign features to nodes or edges\n--------------------------------------------\nGraph neural networks associate features with nodes and edges for training.\nFor our classification example, we assign each node's an input feature as a one-hot vector:\nnode $v_i$'s feature vector is $[0,\\ldots,1,\\dots,0]$,\nwhere the $i^{th}$ position is one.\n\nIn DGL, we can add features for all nodes at once, using a feature tensor that\nbatches node features along the first dimension. This code below adds the one-hot\nfeature for all nodes:\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba22ec50f3aff4c1a680c8b7c834bbd62541750d"
      },
      "cell_type": "code",
      "source": "import torch\n\nG.ndata['feat'] = torch.eye(34)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f2f38d7550a081e8fb760a95e8bf864754ab378e"
      },
      "cell_type": "markdown",
      "source": "We can print out the node features to verify:\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1cbbe36ceb741edd08b49e8b483d80103f5aadd7"
      },
      "cell_type": "code",
      "source": "# print out node 2's input feature\nprint(G.nodes[2].data['feat'])\n\n# print out node 10 and 11's input features\nprint(G.nodes[[10, 11]].data['feat'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c8dde43fb9ba1bf846511e5ed1bab6ef68d484b3"
      },
      "cell_type": "code",
      "source": "import torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n# Define the message & reduce function\n# NOTE: we ignore the GCN's normalization constant c_ij for this tutorial.\ndef gcn_message(edges):\n    # The argument is a batch of edges.\n    # This computes a (batch of) message called 'msg' using the source node's feature 'h'.\n    return {'msg' : edges.src['h']}\n\ndef gcn_reduce(nodes):\n    # The argument is a batch of nodes.\n    # This computes the new 'h' features by summing received 'msg' in each node's mailbox.\n    return {'h' : torch.sum(nodes.mailbox['msg'], dim=1)}\n\n# Define the GCNLayer module\nclass GCNLayer(nn.Module):\n    def __init__(self, in_feats, out_feats):\n        super(GCNLayer, self).__init__()\n        self.linear = nn.Linear(in_feats, out_feats)\n\n    def forward(self, g, inputs):\n        # g is the graph and the inputs is the input node features\n        # first set the node features\n        g.ndata['h'] = inputs\n        # trigger message passing on all edges \n        g.send(g.edges(), gcn_message)\n        # trigger aggregation at all nodes\n        g.recv(g.nodes(), gcn_reduce)\n        # get the result node features\n        h = g.ndata.pop('h')\n        # perform linear transformation\n        return self.linear(h)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "023f2a72994e0df1062627631d2edf781b6de59c"
      },
      "cell_type": "markdown",
      "source": "In general, the nodes send information computed via the *message functions*,\nand aggregates incoming information with the *reduce functions*.\n\nWe then define a deeper GCN model that contains two GCN layers:\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe46423223a6a7b85d283292bc4df0ed794d88bb"
      },
      "cell_type": "code",
      "source": "# Define a 2-layer GCN model\nclass GCN(nn.Module):\n    def __init__(self, in_feats, hidden_size, num_classes):\n        super(GCN, self).__init__()\n        self.gcn1 = GCNLayer(in_feats, hidden_size)\n        self.gcn2 = GCNLayer(hidden_size, num_classes)\n\n    def forward(self, g, inputs):\n        #h = torch.tanh(inputs)\n        h = self.gcn1(g, inputs)\n        h = torch.tanh(h)\n        h = self.gcn2(g, h)\n        h = torch.tanh(h)\n        return h\n# The first layer transforms input features of size of 34 to a hidden size of 5.\n# The second layer transforms the hidden layer and producres output features of\n# size 2, corresponding to the two groups of the karate club.\nnet = GCN(34, 4, 4)\nprint(net)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ec32effe1e73d653ccf8e7495068cb02e38ec1ab"
      },
      "cell_type": "markdown",
      "source": "Step 4: data preparation and initialization\n-------------------------------------------\n\nWe use one-hot vectors to initialize the node features. Since this is a\nsemi-supervised setting, only the instructor (node 0) and the club president\n(node 33) are assigned labels. The implementation is available as follow.\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "911df3ff0e3175e1009138b63ed6f4433824ba01",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "inputs = torch.eye(34)\nprint(inputs)\n\nlabeled_nodes = torch.tensor([6,12, 22,33])  # only the instructor and the president nodes are labeled\nprint(labeled_nodes)\nlabels = torch.tensor([0, 1,2,3])\nprint(labels)# their labels are different",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ec7ca7c678e7881388cdcdee33f768e8714a9045"
      },
      "cell_type": "markdown",
      "source": "Step 5: train then visualize\n----------------------------\nThe training loop is exactly the same as other PyTorch models.\nWe (1) create an optimizer, (2) feed the inputs to the model,\n(3) calculate the loss and (4) use autograd to optimize the model.\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0e59506b13269454f7343c2bf1c978f2d04e257",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nall_logits = []\nfor epoch in range(201):\n    logits = net(G, inputs)\n    # we save the logits for visualization later\n    #print(\"log\",logits)\n    all_logits.append(logits.detach())\n  \n    logp = F.log_softmax(logits, 1)\n    # we only compute loss for labeled nodes\n    loss = F.nll_loss(logp[labeled_nodes], labels)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))\n#print(all_logits[0][0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c8a211984004e6ba804307f630fdcffe24dfa61b"
      },
      "cell_type": "markdown",
      "source": "This is a rather toy example, so it does not even have a validation or test\nset. Instead, Since the model produces an output feature of size 2 for each node, we can\nvisualize by plotting the output feature in a 2D space.\nThe following code animates the training process from initial guess\n(where the nodes are not classified correctly at all) to the end\n(where the nodes are linearly separable).\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47f84576b8b34153f3e7835cbc4552379a52bfa0"
      },
      "cell_type": "code",
      "source": "from sklearn.manifold import TSNE\nfrom matplotlib import pyplot as plt\ntsne_data1=[]\ni=0\nepochess=[]\nwhile(i<201):\n    outp=all_logits[i]\n    data_1000=outp\n#labels_1000=labels\n#print(labels)\n    md=TSNE(n_components=2,random_state=0,perplexity = 2,learning_rate  = 100, n_iter=5000)\n\n    tsne_data=md.fit_transform(data_1000)\n    tsne_data1.append(tsne_data.tolist())\n    epochess.append(i)\n    i=i+1\n#print(len(tsne_data1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ca9f56857461758337c85bd5a29a57a2a15cee5"
      },
      "cell_type": "code",
      "source": "labels=[0, 1, 1, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c901c2fbeb1868efd9a9801bfde9f43f10a37733",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "print(len(all_logs[0][0]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6acc335aab5491c1c6e17809f253acf5123f365"
      },
      "cell_type": "code",
      "source": "\nimport matplotlib.animation as animation\nimport matplotlib.pyplot as plt\npos = nx.kamada_kawai_layout(nx_G)\nepoc=[]\ngroup=[]\ndef draw(i):\n    cls1color = '#9B59B6'\n    cls2color = '#F7DC6F'\n    cls3color = '#A2D9CE'\n    cls4color = '#7F8C8D'\n    cls5color = '#D98880'\n    cls6color = '#FF00FF'\n    \n    pos = {}\n    dos = {}\n    colors = []\n    #pod=[]\n    #ld=[]\n    lab=[]\n    for v in range(34):\n        ld=[]\n        \n        #print(v)\n        #print(\"all\", all_logits[i][v])\n        dos[v] = all_logits[i][v].numpy()\n        #print(pos[v])\n        cls = dos[v].argmax() # returns index of highest \n        lab.append(cls)\n        \n        #a=np.array((all_logs[i][v]))\n        #pos[v] = a\n        a=np.array(tsne_data1[i][v])\n        pos[v] = tsne_data1[i][v]\n        #print(\"cls\",cls)\n        #print(pos[v])\n        if(cls==0):\n            colors.append(cls1color)\n        elif(cls==1):\n            colors.append(cls2color)\n        elif(cls==2):\n            colors.append(cls3color)\n        elif(cls==3):\n            colors.append(cls4color)  \n        epoc.append(i)\n        #print(pos)\n    group.append(lab)\n        #colors.append(cls1color if cls else cls2color elif ) # according to the index can give color\n    ax.cla()\n    ax.axis('off')\n    ax.set_title('Epoch: %d' % i)\n    #pos = nx.kamada_kawai_layout(nx_G)\n    \n    #nx.draw_networkx(nx_G.to_undirected(), pos, node_color=colors,\n           # with_labels=False, node_size=100, ax=ax)\n    nx.draw_networkx(nx_G.to_undirected(), pos, node_color=colors,\n           with_labels=False, node_size=50, ax=ax)\n    \n    #print(\"eeeeee\",pos)\n    \nfig = plt.figure(dpi=150)\nfig.clf()\nax = fig.subplots()\n # draw the prediction of the first epoch\n\ndraw(200)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "35fa6a32b2991685a1bc40c3393edec1cbf9352d"
      },
      "cell_type": "markdown",
      "source": "\n"
    },
    {
      "metadata": {
        "_uuid": "c25f251abe5dfa3eb879b0ad2dc21f85b4612b3c"
      },
      "cell_type": "markdown",
      "source": "The following animation shows how the model correctly predicts the community\nafter a series of training epochs.\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90eddb62f3c59353ccf0ac7b281a38c16be4aef1",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "ani = animation.FuncAnimation(fig, draw, frames=len(all_logits), interval=201)\nani.save('pickup_animation.gif', writer='imagemagick', fps=10)\n#plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ddded88651cc6797caab40ba05c5b7642916c182"
      },
      "cell_type": "code",
      "source": "from sklearn.manifold import TSNE\nfrom matplotlib import pyplot as plt\nimport pandas as pd\ni = 0\nwhile i<201:\n    outp=all_logits[i]\n    data_1000=outp\n#labels_1000=labels\n    print(group[i])\n    md=TSNE(n_components=2,random_state=0,perplexity = 2,learning_rate  = 100, n_iter=5000)\n\n    tsne_data1=md.fit_transform(data_1000)#Apply TSNE on the 190 iter\n    tsne_data1=np.vstack((labels,tsne_data1.T)).T #Stack \n    tsne_df=pd.DataFrame(data=tsne_data1,columns=[\"label\",\"Dim_1\",\"Dim_2\"])\n    tsne_df[\"Epochs\"] = i\n    #print(tsne_df)\n    #print(tsne_df)\n    #with open(\"output.csv\", 'w+') as f:\n        #tsne_df.to_csv(f, header=False)\n    export_csv = tsne_df.to_csv ('files190.csv',mode=\"a\", index = None, header=False)\n    print(\"iteraction - \", i)\n    i = i+10",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4999aaec60b21278885e827de3ac8bab3a196715"
      },
      "cell_type": "markdown",
      "source": "\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}